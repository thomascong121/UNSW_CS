{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9318 Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. This note book contains instructions for **COMP9318-Lab4**.\n",
    "\n",
    "* You are required to complete your implementation in a file `submission.py` provided along with this notebook.\n",
    "\n",
    "* You are not allowed to print out unnecessary stuff. We will not consider any output printed out on the screen. All results should be returned in appropriate data structures via corresponding functions.\n",
    "\n",
    "* You can submit your implementation for **Lab4** via following link: https://kg.cse.unsw.edu.au/submit/ .\n",
    "\n",
    "* For each question, we have provided you with detailed instructions along with question headings. In case of any problem, you can post your query @ Piazza.\n",
    "\n",
    "* You are allowed to add other functions and/or import modules (you may have to in this lab), but you are not allowed to define global variables. **Only functions are allowed** in `submission.py`. \n",
    "\n",
    "* You should not import unnecessary modules/libraries, failing to import such modules at test time will lead to errors.\n",
    "\n",
    "* We will provide immediate feedback on your submission. You can access your scores using the online submission portal on the same day. \n",
    "\n",
    "* For **Final Evaluation** we will be using a different dataset, so your final scores may vary.  \n",
    "\n",
    "* You are allowed to submit as many times as you want before the deadline, but **ONLY the latest version will be kept and marked**.\n",
    "\n",
    "* Submission deadline for this assignment is **23:59:59 on 16th April, 2019**. We will **not** accept any late submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-1: Text Classification using Multinomial Naive Bayes\n",
    "\n",
    "You are required to implement a multinomial naive bayes classifier to predict spam SMS.\n",
    "\n",
    "The training data is a set of SMS categoried into `spam` and `ham`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv('./asset/data.txt', sep='\\t')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement a unigram model, first we tokenize the text. We use the count corresponding to each token (word) in the SMS as its feature (i.e., bag of words). We store the features and catrgorical information for each SMS in a `dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sms):\n",
    "    return sms.split(' ')\n",
    "\n",
    "def get_freq_of_tokens(sms):\n",
    "    tokens = {}\n",
    "    for token in tokenize(sms):\n",
    "        if token not in tokens:\n",
    "            tokens[token] = 1\n",
    "        else:\n",
    "            tokens[token] += 1\n",
    "    return tokens\n",
    "\n",
    "training_data = []\n",
    "for index in range(len(raw_data)):\n",
    "    training_data.append((get_freq_of_tokens(raw_data.iloc[index].text), raw_data.iloc[index].category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, you need to **implement** a multinomial naive bayes classifier (i.e., `multinomial_nb()` in the file: `submission.py`) with add-1 smoothing. The input arguments of `multinomial_nb()` are:\n",
    "* `training_data`: pre-processed data stored as a `dictionary`\n",
    "* `sms`: test-sms (i.e., a list of tokens) that you need to categorize as `spam` and/or `ham`\n",
    "\n",
    "The return value of `multinomial_nb()` should be the **ratio** of the probability of sms is spam and the probability of sms is ham. A return value larger than 1 implies the `sms` is spam and vice versa.\n",
    "\n",
    "For example, a sample output is shown in the cell given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2342767295597484\n"
     ]
    }
   ],
   "source": [
    "## How we test your implementation...\n",
    "import submission_ans as submission\n",
    "\n",
    "sms = 'I am not spam'\n",
    "print(submission.multinomial_nb(training_data, tokenize(sms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Test Environment\n",
    "\n",
    "For testing, we have pre-installed the requisite modules and/or libraries in the testing environment. You are only allowed to use following libraries:\n",
    "* python: 3.6.5\n",
    "* pandas: 0.19.2\n",
    "\n",
    "NOTE: You are required to implement the classifier by yourself. You are not allowed to import **sklearn** and/or any other library in Lab4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two(x,y):\n",
    "    if(x == {}):\n",
    "        return y\n",
    "    if(y == {}):\n",
    "        return x\n",
    "    l = list(x.keys())+list(y.keys())\n",
    "    z={}\n",
    "    for i in l:\n",
    "        if(i in y and i in x):\n",
    "            z[i] = x[i]+y[i]\n",
    "        elif(i in x):\n",
    "            z[i] = x[i]\n",
    "        else:\n",
    "            z[i] = y[i]\n",
    "    return z\n",
    "        \n",
    "            #0.2342767295597484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "def multinomial_nb(training_data,sms):\n",
    "    #calculate class probability\n",
    "    Pham=0\n",
    "    Pspam=0\n",
    "    hamList=[]\n",
    "    spamList=[]\n",
    "    for i in training_data:\n",
    "        if(list(i)[1]=='ham'):\n",
    "            Pham+=1\n",
    "            hamList.append(list(i)[0])\n",
    "        else:\n",
    "            spamList.append(list(i)[0])\n",
    "            Pspam+=1\n",
    "    Pham = Pham/(len(training_data))\n",
    "    Pspam = Pspam/(len(training_data))\n",
    "    \n",
    "    ###Probability of each word per class\n",
    "    result_ham = {}\n",
    "    result_spam = {}\n",
    "    #when ham show all words\n",
    "    for d_1 in hamList:\n",
    "        result_ham = merge_two(result_ham,d_1)\n",
    "    #when spam show all words\n",
    "    for d_2 in spamList:\n",
    "        result_spam = merge_two(result_spam,d_2)\n",
    "    #number of  words ham class\n",
    "    s_ham = sum(result_ham.values())\n",
    "    #number of  words spam class\n",
    "    s_spam = sum(result_spam.values())\n",
    "    #occuency of each word\n",
    "    result_total = result_ham.copy()\n",
    "    result_total.update(result_spam)\n",
    "\n",
    "    total_words = len(result_total)\n",
    "    #calculate the Probability of each word in spam/ham class\n",
    "    #ham:\n",
    "    Prob_word_ham={}\n",
    "    for word in result_total:\n",
    "        if(word in result_ham):\n",
    "            Prob_word_ham[word] = (result_ham[word]+1)/(s_ham+total_words)\n",
    "        else:\n",
    "            Prob_word_ham[word] = 1/(s_ham+total_words)\n",
    "    #spam:\n",
    "    Prob_word_spam={}\n",
    "    for word in result_total:\n",
    "        if(word in result_spam):\n",
    "            Prob_word_spam[word] = (result_spam[word]+1)/(s_spam+total_words)\n",
    "        else:\n",
    "            Prob_word_spam[word] = 1/(s_spam+total_words)     \n",
    "    #prediction\n",
    "    #spam probability\n",
    "    product = 1\n",
    "    for word in sms:\n",
    "        if(word in Prob_word_spam):\n",
    "            product = product*Prob_word_spam[word]\n",
    "    spam_pro = Pspam*product\n",
    "    product = 1\n",
    "    #ham probability\n",
    "    for word in sms:\n",
    "        if(word in Prob_word_ham):\n",
    "            product = product*Prob_word_ham[word]\n",
    "    ham_pro = Pham*product    \n",
    "    print('spam prob is:',spam_pro)\n",
    "    print('ham prob is:',ham_pro)\n",
    "\n",
    "    return spam_pro/ham_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam prob is: 0.0020964360587002098\n",
      "ham prob is: 0.008948545861297539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23427672955974846"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = 'I am not spam'\n",
    "multinomial_nb(training_data, tokenize(sms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
